{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subreddit                                              title  \\\n",
      "0  AskReddit                2024 United States Elections Thread   \n",
      "1  AskReddit  What is the worst atrocity committed in human ...   \n",
      "2  AskReddit  If the World was told there was a 25% chance t...   \n",
      "3  AskReddit          What instantly kills the vibe at a party?   \n",
      "4  AskReddit  Whatâ€™s the most disgusting thing you've ever h...   \n",
      "\n",
      "                                             content  upvotes  upvote_ratio  \\\n",
      "0  Please use this thread to discuss the ongoing ...      122          0.70   \n",
      "1                                                NaN     4263          0.87   \n",
      "2                                                NaN      717          0.92   \n",
      "3                                                NaN      289          0.92   \n",
      "4                                                NaN      620          0.86   \n",
      "\n",
      "   comments_count               author            timestamp  post_id  \n",
      "0            7415  AskRedditModerators  2024-11-05 17:14:10  1gkk9s3  \n",
      "1            5181          SGTRock4602  2024-11-14 08:18:38  1gr5rox  \n",
      "2            1238            bydevilz1  2024-11-14 13:54:02  1grdlgd  \n",
      "3            1040         OberynOswald  2024-11-14 18:29:31  1grjqr2  \n",
      "4            3082         MorrisDeGoat  2024-11-14 13:48:33  1grdgv3  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"subreddit_posts.csv\")\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subreddit', 'title', 'content', 'upvotes', 'upvote_ratio',\n",
       "       'comments_count', 'author', 'timestamp', 'post_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18049, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AskReddit', 'ChangeMyView', 'TodayILearned', 'self', 'offmychest', 'Showerthoughts', 'personalfinance', 'AskScience', 'Writing', 'Advice', 'LetsNotMeet', 'SelfImprovement', 'DecidingToBeBetter', 'AskHistorians', 'TwoXChromosomes', 'CasualConversation', 'InternetIsBeautiful', 'nosleep', 'WritingPrompts', 'ExplainLikeImFive', 'TrueOffMyChest', 'UnpopularOpinion', 'relationships', 'TrueAskReddit', 'Confession', 'ShortScaryStories', 'ProRevenge', 'NuclearRevenge', 'LifeProTips', 'needadvice', 'TrueUnpopularOpinion']\n"
     ]
    }
   ],
   "source": [
    "unique_subreddits_list = df['subreddit'].unique().tolist()\n",
    "print(unique_subreddits_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subreddit: 0 null values\n",
      "title: 0 null values\n",
      "content: 3043 null values\n",
      "upvotes: 0 null values\n",
      "upvote_ratio: 0 null values\n",
      "comments_count: 0 null values\n",
      "author: 0 null values\n",
      "timestamp: 0 null values\n",
      "post_id: 0 null values\n"
     ]
    }
   ],
   "source": [
    "# Get the count of null values in each column and print with column names\n",
    "null_values = df.isnull().sum()\n",
    "\n",
    "# Display column names with their null count\n",
    "for column, count in null_values.items():\n",
    "    print(f\"{column}: {count} null values\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where 'content' column has null values\n",
    "df = df.dropna(subset=['content'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subreddit: 0 null values\n",
      "title: 0 null values\n",
      "content: 0 null values\n",
      "upvotes: 0 null values\n",
      "upvote_ratio: 0 null values\n",
      "comments_count: 0 null values\n",
      "author: 0 null values\n",
      "timestamp: 0 null values\n",
      "post_id: 0 null values\n"
     ]
    }
   ],
   "source": [
    "null_values = df.isnull().sum()\n",
    "\n",
    "# Display column names with their null count\n",
    "for column, count in null_values.items():\n",
    "    print(f\"{column}: {count} null values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15006, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you already have your DataFrame 'df'\n",
    "# Sample DataFrame with the given columns\n",
    "# df = pd.read_csv(\"your_existing_file.csv\")  # Replace with your actual DataFrame\n",
    "\n",
    "# Convert 'timestamp' to datetime with automatic format inference\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "\n",
    "# Extract Date, Time, and AM/PM\n",
    "df['date'] = df['timestamp'].dt.date\n",
    "df['time'] = df['timestamp'].dt.strftime('%I:%M')  # Time in the format \"HH:MM AM/PM\"\n",
    "df['AM_PM'] = df['timestamp'].dt.strftime('%p')  # Extract AM or PM\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15006, 12)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        subreddit                                              title  \\\n",
      "0       AskReddit                2024 United States Elections Thread   \n",
      "858  ChangeMyView  Meta: Research Collaboration Opportunity with ...   \n",
      "859  ChangeMyView  CMV: Goodhearted \"cultural appropriation\" is f...   \n",
      "860  ChangeMyView  CMV: Anyone given a life sentence should also ...   \n",
      "861  ChangeMyView  CMV: Most people are too lazy to actually seek...   \n",
      "\n",
      "                                               content  upvotes  upvote_ratio  \\\n",
      "0    Please use this thread to discuss the ongoing ...      122          0.70   \n",
      "858  From time to time, CMV will partner with profe...        7          0.71   \n",
      "859  I am Austrian and when non-Austrians find a li...      132          0.85   \n",
      "860  Anyone given a life sentence should also be gi...       45          0.84   \n",
      "861  I always see people online talking about how t...      123          0.84   \n",
      "\n",
      "     comments_count               author           timestamp  post_id  \\\n",
      "0              7415  AskRedditModerators 2024-11-05 17:14:10  1gkk9s3   \n",
      "858               9              Ansuz07 2024-10-30 10:42:19  1gfpl4m   \n",
      "859              69  Possible_Lemon_9527 2024-11-14 19:30:43  1grkyyp   \n",
      "860              38     Christ-The-Slave 2024-11-14 19:39:44  1grl5em   \n",
      "861              61   Neckties-Over-Bows 2024-11-14 12:39:25  1grbu7n   \n",
      "\n",
      "           date   time AM_PM  upvote_ratio_normalized  \\\n",
      "0    2024-11-05  05:14    PM                 0.684211   \n",
      "858  2024-10-30  10:42    AM                 0.694737   \n",
      "859  2024-11-14  07:30    PM                 0.842105   \n",
      "860  2024-11-14  07:39    PM                 0.831579   \n",
      "861  2024-11-14  12:39    PM                 0.831579   \n",
      "\n",
      "     comments_count_normalized  upvotes_normalized  \n",
      "0                     0.443322            0.004664  \n",
      "858                   0.000538            0.000268  \n",
      "859                   0.004125            0.005046  \n",
      "860                   0.002272            0.001720  \n",
      "861                   0.003647            0.004702  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Assuming your dataframe 'df' is already loaded with the necessary columns\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Select the columns to normalize\n",
    "columns_to_normalize = ['upvote_ratio', 'comments_count', 'upvotes']\n",
    "\n",
    "# Apply the scaler to the selected columns and create new columns\n",
    "df[['upvote_ratio_normalized', 'comments_count_normalized', 'upvotes_normalized']] = scaler.fit_transform(df[columns_to_normalize])\n",
    "\n",
    "# Display the updated DataFrame with the new normalized columns\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'author', 'timestamp', and 'post_id' columns\n",
    "# df = df.drop(columns=['author', 'timestamp', 'post_id'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = df['title'].str.replace(r'\\W', ' ').str.lower()\n",
    "df['content'] = df['content'].str.replace(r'\\W', ' ').str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.tokenize import word_tokenize\n",
    "# df['title_tokens'] = df['title'].apply(word_tokenize)\n",
    "# df['content_tokens'] = df['content'].apply(word_tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15006, 15)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cleaned_labeled_subreddit_posts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df['upvotes'] < df['upvotes'].quantile(0.95)]  # Removing top 5% of extreme values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert the entire DataFrame to JSON format and save it to a file\n",
    "# df.to_json(\"data.json\", orient='records', lines=True)\n",
    "\n",
    "# # Notify the user that the file has been saved\n",
    "# print(\"Data has been saved to 'data.json'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
